{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_35 = OpenAI(model=\"gpt-3.5-turbo-0613\")\n",
    "llm_4 = OpenAI(model=\"gpt-4-0613\")\n",
    "# base_agent = ReActAgent.from_tools(query_engine_tools, llm=llm_35, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.query.query_transform.base import (\n",
    "    StepDecomposeQueryTransform,\n",
    ")\n",
    "\n",
    "# gpt-4\n",
    "step_decompose_transform = StepDecomposeQueryTransform(llm=llm_4, verbose=True)\n",
    "\n",
    "# gpt-3\n",
    "step_decompose_transform_gpt3 = StepDecomposeQueryTransform(\n",
    "    llm=llm_35, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"./query-decomposition/data/filler\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents, llm=llm_35, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_summary = \"Used to answer questions about the teacher, the students, and the classroom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.finetuning.callbacks import OpenAIFineTuningHandler\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "from llama_index.core.agent import ReActAgent\n",
    "\n",
    "finetuning_handler = OpenAIFineTuningHandler()\n",
    "callback_manager = CallbackManager([finetuning_handler])\n",
    "\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# limit the context window artifically to test refine process\n",
    "Settings.context_window = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "from llama_index.core.query_engine import MultiStepQueryEngine\n",
    "\n",
    "query_engine = index.as_query_engine(llm=llm_4)\n",
    "query_engine = MultiStepQueryEngine(\n",
    "    query_engine=query_engine,\n",
    "    query_transform=step_decompose_transform,\n",
    "    index_summary=index_summary,\n",
    ")\n",
    "\n",
    "query_engine.callback_manager = callback_manager\n",
    "query_engine.callback_manager.add_handler(finetuning_handler)\n",
    "query_engine.callback_manager.start_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = './query-decomposition/cv_loc_enhanced_questions.json'\n",
    "with open(file_path, 'r') as file_loc:\n",
    "    data = json.load(file_loc)\n",
    "\n",
    "new_questions = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_questions(questions, path):\n",
    "    with open(path, \"w\") as f:\n",
    "        for question in questions:\n",
    "            f.write(question + \"\\n\")\n",
    "            \n",
    "def load_questions(path):\n",
    "    questions = []\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            questions.append(line.strip())\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: split up into cv and loc questions, also train on each possible set of eval/test split\n",
    "train_questions, eval_questions = new_questions[:60], new_questions[60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_questions(train_questions, \"train_questions_10q.txt\")\n",
    "save_questions(eval_questions, \"eval_questions_10q.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_questions = load_questions(\"train_questions_10q.txt\")\n",
    "eval_questions = load_questions(\"eval_questions_10q.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=query_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"documents\",\n",
    "            description=\"Query engine that decomposes one complex query into its parts\",\n",
    "        ),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-4-0613\")\n",
    "gpt4_agent = ReActAgent.from_tools(\n",
    "    query_engine_tools,\n",
    "    llm=llm,\n",
    "    callback_manager=callback_manager,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change Index of train_questions[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "for idx, question in enumerate(train_questions[41:]):\n",
    "    print(f\"[{idx}] Question: {question}\")\n",
    "    response = query_engine.query(question)\n",
    "    responses.append(response)\n",
    "    print(f\"[{idx}] Response: {str(response)}\")\n",
    "\n",
    "# question = train_questions[0]\n",
    "# response_gpt4 = query_engine.query(\n",
    "#     \"Is the teacher standing in front of the classroom while giving a lecture or conducting an activity?\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_engine.callback_manager.end_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for response in responses:   \n",
    "    sub_qa = response.metadata[\"sub_qa\"]\n",
    "    tuples = [(t[0], t[1]) for t in sub_qa]\n",
    "    if len(tuples) > 0:\n",
    "        latest_tuple = tuples[-1]\n",
    "        latest_query = latest_tuple[0]\n",
    "    print(latest_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_handler.save_finetuning_events(\"finetuning_events_10q.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.finetuning import OpenAIFinetuneEngine\n",
    "\n",
    "finetune_engine = OpenAIFinetuneEngine(\n",
    "    \"gpt-3.5-turbo\",\n",
    "    \"finetuning_events_10q.jsonl\",\n",
    "    #start_job_id=\"<start-job-id>\"  # if you have an existing job, can specify id here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_engine.finetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_llm = finetune_engine.get_finetuned_model(temperature=0.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
