{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e0768d5",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jerryjliu/llama_index/blob/main/docs/examples/query_transformations/SimpleIndexDemo-multistep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c48213d-6e6a-4c10-838a-2a7c710c3a05",
   "metadata": {},
   "source": [
    "# Multi-Step Query Engine\n",
    "\n",
    "We have a multi-step query engine that's able to decompose a complex query into sequential subquestions. This\n",
    "guide walks you through how to set it up!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc77f986",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a71098",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-llms-openai\n",
    "%pip install llama-index-agent-openai\n",
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5885d63",
   "metadata": {},
   "source": [
    "#### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4ace96",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d3b817-b70e-4667-be4f-d3a0fe4bd119",
   "metadata": {},
   "source": [
    "#### Load documents, build the VectorStoreIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ebfca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690a6918-7c75-4f95-9ccc-d2c4a1fe00d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48da73f-aadb-480c-8db1-99c915b7cc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM (gpt-3.5)\n",
    "gpt35 = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# LLM (gpt-4)\n",
    "gpt4 = OpenAI(temperature=0, model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d1691e-544b-454f-825b-5ee12f7faa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad144ee7-96da-4dd6-be00-fd6cf0c78e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6caf93b-6345-4c65-a346-a95b0f1746c4",
   "metadata": {},
   "source": [
    "#### Query Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d989ba-0c1d-43b6-a1d3-0ea7135f43a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.query.query_transform.base import (\n",
    "    StepDecomposeQueryTransform,\n",
    ")\n",
    "\n",
    "# gpt-4\n",
    "step_decompose_transform = StepDecomposeQueryTransform(llm=gpt4, verbose=True)\n",
    "\n",
    "# gpt-3\n",
    "step_decompose_transform_gpt3 = StepDecomposeQueryTransform(llm=gpt35, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a124db0-e2d7-4566-bcec-1d41cf669ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_summary = \"Used to answer questions about the author\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85466fdf-93f3-4cb1-a5f9-0056a8245a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "from llama_index.core.query_engine import MultiStepQueryEngine\n",
    "\n",
    "query_engine = index.as_query_engine(llm=gpt4)\n",
    "query_engine = MultiStepQueryEngine(\n",
    "    query_engine=query_engine,\n",
    "    query_transform=step_decompose_transform,\n",
    "    index_summary=index_summary,\n",
    ")\n",
    "response_gpt4 = query_engine.query(\n",
    "    \"Who was in the first batch of the accelerator program the author\" \" started?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7MeeUrf1xQcl",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_qa = response_gpt4.metadata[\"sub_qa\"]\n",
    "tuples = [(t[0], t[1].response) for t in sub_qa]\n",
    "print(tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sA96XR4qxtYh",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_tuple = tuples[-1]\n",
    "latest_query = latest_tuple[0]\n",
    "print(latest_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iRiYf_rJy5Vb",
   "metadata": {},
   "source": [
    "New Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X2-aHSfByGyw",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NCsUXEuqyI2S",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.response.pprint_utils import pprint_response\n",
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MdBfe2CEyKl-",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff_byYewyL5K",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = index.as_query_engine(similarity_top_k=3, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kwjUemE5yTVB",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "\n",
    "query_tool_pg = QueryEngineTool.from_defaults(\n",
    "    query_engine=engine,\n",
    "    name=\"files\",\n",
    "    description=(f\"Paul graham essay\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EZi7FVbwydNQ",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define query plan tool\n",
    "from llama_index.core.tools import QueryPlanTool\n",
    "from llama_index.core import get_response_synthesizer\n",
    "\n",
    "response_synthesizer = get_response_synthesizer()\n",
    "query_plan_tool = QueryPlanTool.from_defaults(\n",
    "    query_engine_tools=[query_tool_pg],\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DV9tC4DQyexP",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_plan_tool.metadata.to_openai_tool()  # to_openai_function() deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MPEwUMaAygE-",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    [query_plan_tool],\n",
    "    max_function_calls=10,\n",
    "    llm=OpenAI(temperature=0, model=\"gpt-4-0613\"),\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HGEzQEupyh9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.query(latest_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-IOyxIjpymvH",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
